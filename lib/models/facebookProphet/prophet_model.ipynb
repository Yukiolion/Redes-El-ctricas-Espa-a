{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7faeb5f8",
   "metadata": {},
   "source": [
    "AQUI SE HARAN PREDICCIONES CON EL MODELO DE PROPHET ENTRENADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea07caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "import plotly.express as px\n",
    "# CONFIGURAMOS QUE LOS GRAFICOS SE ABRAN EN WEB PARA PODER VERLOS INTERACTIVOS\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_model():\n",
    "    df = pd.read_csv('../data/demanda-depurado.csv')\n",
    "\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    df = df.sort_values('fecha')\n",
    "\n",
    "    # LISTA VACIA PARA AÑADIR LOS VALORES DE LAS PREDICCIONES POR REGION.\n",
    "    predicciones = []\n",
    "\n",
    "    for (region, indicador), grupo in df.groupby(['region', 'indicador']):\n",
    "        # FILTRAR POR REGION E INDICADOR PARA HACER UNO A LA VEZ.\n",
    "        df_filtrado = grupo[['fecha', 'valor']].rename(columns={'fecha': 'ds', 'valor': 'y'})\n",
    "\n",
    "        # PREPARACIÓN DE LOS DATOS.\n",
    "        df_filtrado = df_filtrado.dropna()\n",
    "        df_filtrado = df_filtrado[np.isfinite(df_filtrado['y'])]\n",
    "\n",
    "        # HAREMOS UNA LIMPIEZA DE DATOS ALGO AGRESIVA DEBIDO A\n",
    "        # LA GRAN MAGNITUD DE VALORES QUE SE MANEJAN.\n",
    "        z_scores = zscore(df_filtrado['y'])\n",
    "        df_filtrado = df_filtrado[np.abs(z_scores) < 3]\n",
    "\n",
    "        lower_bound = np.percentile(df_filtrado['y'], 1)\n",
    "        upper_bound = np.percentile(df_filtrado['y'], 99)\n",
    "        df_filtrado = df_filtrado[(df_filtrado['y'] >= lower_bound) & (df_filtrado['y'] <= upper_bound)]\n",
    "\n",
    "        # ESCALAMOS LOS DATOS DEBIDO A QUE TIENEN VALORES MUY GRANDES\n",
    "        # Y ASI EVITAMOS QUE EL MODELO TENGA UN COLAPSO INTERNO.\n",
    "        df_filtrado['y'] = np.log(df_filtrado['y'] + 1)\n",
    "\n",
    "        # CONFIGURACIÓN DEL MODELO PROPHET DE META PARA HACER LAS PREDICCIONES.\n",
    "        modelo = Prophet(yearly_seasonality=False, daily_seasonality=True, weekly_seasonality=True)\n",
    "        modelo.fit(df_filtrado)\n",
    "        nombre_archivo = f\"modelo_prophet_{region}.pkl\"\n",
    "        with open(f'../../../models/prophet_models/{nombre_archivo}', 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "        # DEFINIR EL RANGO DE FECHAS A PREDECIR.\n",
    "        rango = 24\n",
    "        future = modelo.make_future_dataframe(periods=rango, freq='D')\n",
    "\n",
    "        forecast = modelo.predict(future)\n",
    "\n",
    "        # GRAFICAS PARA VISUALIZAR LAS PREDICCIONES.\n",
    "        fig1 = plot_plotly(modelo, forecast)\n",
    "        fig1.update_layout(\n",
    "            title=f'Predicción de demanda para {region} usando Prophet',\n",
    "            xaxis_title='Fecha',\n",
    "            yaxis_title='Demanda'\n",
    "        )\n",
    "\n",
    "        fig2 = plot_components_plotly(modelo, forecast)\n",
    "        fig2.update_layout(\n",
    "            title=f'Componentes de la predicción de demanda para {region}',\n",
    "            xaxis_title='Fecha',\n",
    "            yaxis_title='Demanda'\n",
    "        )\n",
    "\n",
    "        fig1.show()\n",
    "        fig2.show()\n",
    "\n",
    "        # HACEMOS LAS PREDICCIONES PARA EL RANGO DE FECHAS SELECCIONADO Y LAS AÑADIMOS A UNA LISTA\n",
    "        # PARA PODER VISUALIZARLAS DESPUES.\n",
    "        df_futuro = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(rango)\n",
    "        predicciones.append(df_futuro)\n",
    "\n",
    "    df_predicciones_totales = pd.concat(predicciones, ignore_index=True)\n",
    "\n",
    "    return df_predicciones_totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3f836b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:03:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "01:03:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:03:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "prophet = prophet_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
